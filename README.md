# Human-to-Robot Interaction: Learning from Video Demonstration for Robot Imitation

### V1.0, December 22th, 2025
**Authors:** [Thanh Nguyen Canh](https://thanhnguyencanh.github.io/), Thanh Tuan Tran, [Xiem HoangVan](https://sites.google.com/site/xiemhoang/), [Nak Young Chong](https://www.jaist.ac.jp/robot/).


LfD4hri is a novel “Human-to-Robot” imitation learning pipeline that enables robots to acquire manipulation skills directly from unstruc- tured video demonstrations, inspired by the human ability to learn by “watching” and “imitating”



# 1. License


If you use IRAF-SLAM in an academic work, please cite:
  
    @article{canh2026human,
      title={Human-to-Robot Interaction: Learning from Video Demonstration for Robot Imitation},
      author={Thanh Nguyen Canh, Thanh Tuan Tran, Xiem HoangVan, and Nak Young Chong},
      journal={}, 
      volume={},
      number={},
      pages={},
      year={2025}
     }

# 2. Prerequisites


# 3. Building  and examples